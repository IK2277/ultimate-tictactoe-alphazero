#!/usr/bin/env python
"""
åˆæœŸè¨­å®šã‚’è¡¨ç¤ºã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import torch
from auto_tune import get_optimal_batch_size, get_optimal_num_workers
from train_network import get_dynamic_learning_rate, RN_EPOCHS, BATCH_SIZE
from self_play_cpp import get_dynamic_game_count
from pv_mcts import get_dynamic_pv_count
import os
from pathlib import Path

print('\n' + '='*60)
print('ğŸ® ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±')
print('='*60)
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    mem_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
    print(f'VRAM: {mem_gb:.1f} GB')
    print(f'CUDA Version: {torch.version.cuda}')
else:
    print('GPU: CPU Only')
print(f'PyTorch Version: {torch.__version__}')

print('\n' + '='*60)
print('âš™ï¸  ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š (Cycle 0)')
print('='*60)
print(f'å­¦ç¿’ç‡ (LR): {get_dynamic_learning_rate(0)} (AlphaZeroæº–æ‹ : OLIVAW)')
print(f'ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: SGD (Momentum 0.9)')
print(f'å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°: {RN_EPOCHS}')
print(f'ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒƒãƒã‚µã‚¤ã‚º: {BATCH_SIZE}')
print(f'L2æ­£å‰‡åŒ–: 1e-4 (weight_decay)')
print(f'Dropout: 0.3 (Policy/Value Head)')

print('\n' + '='*60)
print('ğŸ² MCTS & Self-Playè¨­å®š (Cycle 0)')
print('='*60)
print(f'MCTSãƒãƒƒãƒã‚µã‚¤ã‚º: {get_optimal_batch_size()}')
print(f'MCTSæ¢ç´¢å›æ•°: {get_dynamic_pv_count(0)}')
print(f'ã‚»ãƒ«ãƒ•ãƒ—ãƒ¬ã‚¤ã‚²ãƒ¼ãƒ æ•°: {get_dynamic_game_count(0)}')
print(f'ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {get_optimal_num_workers(aggressive=True)} (aggressive mode)')
print(f'æ¸©åº¦ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚° (AlphaZeroæº–æ‹ ):')
print(f'  è¨“ç·´æ™‚: 0-29æ‰‹ Ï„=1.0, 30æ‰‹ä»¥é™ Ï„â†’0 (æ±ºå®šè«–çš„)')
print(f'  è©•ä¾¡æ™‚: Ï„=0.0 (æœ€å–„æ‰‹ã®ã¿)')

print('\n' + '='*60)
print('ğŸ“Š å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«')
print('='*60)
print('ã€ã‚µã‚¤ã‚¯ãƒ«ãƒ™ãƒ¼ã‚¹ã€‘')
for cycle in [0, 10, 20, 30]:
    lr = get_dynamic_learning_rate(cycle)
    games = get_dynamic_game_count(cycle)
    mcts = get_dynamic_pv_count(cycle)
    print(f'  Cycle {cycle:2d}+: LR={lr:7.5f}, Games={games:4d}, MCTS={mcts:3d}')

print('\nã€ã‚¨ãƒãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ (å„ã‚µã‚¤ã‚¯ãƒ«å†…)ã€‘')
print('  Epoch  1-69:  Ã—1.0 (ãƒ•ãƒ«å­¦ç¿’ç‡)')
print('  Epoch 70-89:  Ã—0.2 (1/5ã«æ¸›è¡°)')
print('  Epoch 90-100: Ã—0.1 (1/10ã«æ¸›è¡°)')

print('\n' + '='*60)
print('ğŸ¯ è©•ä¾¡è¨­å®š')
print('='*60)
print('è©•ä¾¡è©¦åˆæ•°: 100è©¦åˆ')
print('å¯¾æˆ¦ç›¸æ‰‹: ãƒ©ãƒ³ãƒ€ãƒ ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼')
print('æ›´æ–°é–¾å€¤: 55% (å‹ç‡)')
print('è©•ä¾¡æ¸©åº¦: Ï„=0.0 (æ±ºå®šè«–çš„ã€AlphaZeroæº–æ‹ )')

print('\n' + '='*60)
print('âœ… ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ…‹')
print('='*60)
data_files = len(list(Path('data').glob('*.history')))
model_files = len(list(Path('model').glob('*.pth')))
checkpoint = os.path.exists('training_checkpoint.json')
log_exists = os.path.exists('training.log')

print(f'ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« (.history): {data_files}')
print(f'ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« (.pth): {model_files}')
print(f'ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: {"å­˜åœ¨" if checkpoint else "ãªã— (æ–°è¦é–‹å§‹)"}')
print(f'ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {"å­˜åœ¨" if log_exists else "ãªã— (æ–°è¦ä½œæˆ)"}')

print('\n' + '='*60)
print('ğŸš€ æº–å‚™å®Œäº†ï¼å­¦ç¿’ã‚’é–‹å§‹ã§ãã¾ã™')
print('='*60)
print('ã€æ¨å¥¨ã€‘ãƒ­ã‚°ä»˜ãã§å®Ÿè¡Œ:')
print('  python train_with_log.py')
print()
print('ã€ã‚·ãƒ³ãƒ—ãƒ«ã€‘ç›´æ¥å®Ÿè¡Œ:')
print('  python train_cycle.py')
print()
print('ã€ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã€‘åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§:')
print('  python monitor_simple.py  # ã‚°ãƒ©ãƒ•è¡¨ç¤º')
print('  python monitor_gpu.py     # GPUç›£è¦–')
print('='*60 + '\n')
