Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using C++ backend for MCTS
Model saved to './model/best.pth'
>> Starting from cycle 0

Train 0 ====================================
>> Game Count: 500
>> MCTS Simulations: 100
>> Learning Rate: 0.001
>> Starting parallel self-play with 8 workers (C++ backend)
>> Total games: 500, Games per worker: 62
>> MCTS batch size: 32, PV evaluate count: 100
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 3: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 6: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 8: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 2: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 4: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 1: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 5: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 7: 10/62 games completed
Worker 3: 20/63 games completed
Worker 2: 20/63 games completed
Worker 6: 20/62 games completed
Worker 8: 20/62 games completed
Worker 4: 20/63 games completed
Worker 1: 20/63 games completed
Worker 5: 20/62 games completed
Worker 7: 20/62 games completed
Worker 3: 30/63 games completed
Worker 6: 30/62 games completed
Worker 2: 30/63 games completed
Worker 4: 30/63 games completed
Worker 1: 30/63 games completed
Worker 8: 30/62 games completed
Worker 5: 30/62 games completed
Worker 7: 30/62 games completed
Worker 3: 40/63 games completed
Worker 6: 40/62 games completed
Worker 2: 40/63 games completed
Worker 4: 40/63 games completed
Worker 1: 40/63 games completed
Worker 8: 40/62 games completed
Worker 5: 40/62 games completed
Worker 3: 50/63 games completed
Worker 7: 40/62 games completed
Worker 6: 50/62 games completed
Worker 2: 50/63 games completed
Worker 1: 50/63 games completed
Worker 4: 50/63 games completed
Worker 8: 50/62 games completed
Worker 5: 50/62 games completed
Worker 3: 60/63 games completed
Worker 7: 50/62 games completed
Worker 2: 60/63 games completed
Worker 6: 60/62 games completed
Worker 1: 60/63 games completed
Worker 4: 60/63 games completed
Worker 8: 60/62 games completed
Worker 5: 60/62 games completed
Worker 7: 60/62 games completed
>> Collected 26198 training samples from 500 games
>> Saved to ./data/20251030153546.history
>> Train 0
>> Learning Rate: 0.001
Epoch 1/100, Loss: 2.3468, LR: 0.001000
Epoch 2/100, Loss: 1.1093, LR: 0.001000
Epoch 3/100, Loss: 1.0882, LR: 0.001000
Epoch 4/100, Loss: 1.0088, LR: 0.001000
Epoch 5/100, Loss: 0.9745, LR: 0.001000
Epoch 6/100, Loss: 0.9620, LR: 0.001000
Epoch 7/100, Loss: 0.9546, LR: 0.001000
Epoch 8/100, Loss: 0.9471, LR: 0.001000
Epoch 9/100, Loss: 0.9415, LR: 0.001000
Epoch 10/100, Loss: 1.0002, LR: 0.001000
Epoch 11/100, Loss: 1.0042, LR: 0.001000
Epoch 12/100, Loss: 0.9682, LR: 0.001000
Epoch 13/100, Loss: 0.9415, LR: 0.001000
Epoch 14/100, Loss: 0.9326, LR: 0.001000
Epoch 15/100, Loss: 0.9267, LR: 0.001000
Epoch 16/100, Loss: 0.9241, LR: 0.001000
Epoch 17/100, Loss: 0.9215, LR: 0.001000
Epoch 18/100, Loss: 0.9177, LR: 0.001000
Epoch 19/100, Loss: 0.9187, LR: 0.001000
Epoch 20/100, Loss: 0.9404, LR: 0.001000
Epoch 21/100, Loss: 0.9233, LR: 0.001000
Epoch 22/100, Loss: 0.9152, LR: 0.001000
Epoch 23/100, Loss: 0.9125, LR: 0.001000
Epoch 24/100, Loss: 0.9087, LR: 0.001000
Epoch 25/100, Loss: 0.9088, LR: 0.001000
Epoch 26/100, Loss: 0.9082, LR: 0.001000
Epoch 27/100, Loss: 0.9078, LR: 0.001000
Epoch 28/100, Loss: 0.9078, LR: 0.001000
Epoch 29/100, Loss: 0.9059, LR: 0.001000
Epoch 30/100, Loss: 0.9043, LR: 0.001000
Epoch 31/100, Loss: 0.9346, LR: 0.001000
Epoch 32/100, Loss: 1.0100, LR: 0.001000
Epoch 33/100, Loss: 0.9397, LR: 0.001000
Epoch 34/100, Loss: 0.9225, LR: 0.001000
Epoch 35/100, Loss: 0.9130, LR: 0.001000
Epoch 36/100, Loss: 0.9074, LR: 0.001000
Epoch 37/100, Loss: 0.9050, LR: 0.001000
Epoch 38/100, Loss: 0.9024, LR: 0.001000
Epoch 39/100, Loss: 0.8994, LR: 0.001000
Epoch 40/100, Loss: 0.8989, LR: 0.001000
Epoch 41/100, Loss: 0.8978, LR: 0.001000
Epoch 42/100, Loss: 0.8982, LR: 0.001000
Epoch 43/100, Loss: 0.8970, LR: 0.001000
Epoch 44/100, Loss: 0.8961, LR: 0.001000
Epoch 45/100, Loss: 0.8946, LR: 0.001000
Epoch 46/100, Loss: 0.8929, LR: 0.001000
Epoch 47/100, Loss: 0.8946, LR: 0.001000
Epoch 48/100, Loss: 0.8937, LR: 0.001000
Epoch 49/100, Loss: 0.8937, LR: 0.001000
Epoch 50/100, Loss: 0.8928, LR: 0.000500
Epoch 51/100, Loss: 0.8859, LR: 0.000500
Epoch 52/100, Loss: 0.8811, LR: 0.000500
Epoch 53/100, Loss: 0.8798, LR: 0.000500
Epoch 54/100, Loss: 0.8797, LR: 0.000500
Epoch 55/100, Loss: 0.8797, LR: 0.000500
Epoch 56/100, Loss: 0.8802, LR: 0.000500
Epoch 57/100, Loss: 0.8805, LR: 0.000500
Epoch 58/100, Loss: 0.8810, LR: 0.000500
Epoch 59/100, Loss: 0.8815, LR: 0.000500
Epoch 60/100, Loss: 0.8819, LR: 0.000500
Epoch 61/100, Loss: 0.8818, LR: 0.000500
Epoch 62/100, Loss: 0.8818, LR: 0.000500
Epoch 63/100, Loss: 0.8812, LR: 0.000500
Epoch 64/100, Loss: 0.8809, LR: 0.000500
Epoch 65/100, Loss: 0.8811, LR: 0.000500
Epoch 66/100, Loss: 0.8829, LR: 0.000500
Epoch 67/100, Loss: 0.8819, LR: 0.000500
Epoch 68/100, Loss: 0.8802, LR: 0.000500
Epoch 69/100, Loss: 0.8798, LR: 0.000500
Epoch 70/100, Loss: 0.8797, LR: 0.000500
Epoch 71/100, Loss: 0.8800, LR: 0.000500
Epoch 72/100, Loss: 0.8807, LR: 0.000500
Epoch 73/100, Loss: 0.8798, LR: 0.000500
Epoch 74/100, Loss: 0.8795, LR: 0.000500
Epoch 75/100, Loss: 0.8801, LR: 0.000500
Epoch 76/100, Loss: 0.8796, LR: 0.000500
Epoch 77/100, Loss: 0.8794, LR: 0.000500
Epoch 78/100, Loss: 0.8799, LR: 0.000500
Epoch 79/100, Loss: 0.8796, LR: 0.000500
Epoch 80/100, Loss: 0.8791, LR: 0.000250
Epoch 81/100, Loss: 0.8775, LR: 0.000250
Epoch 82/100, Loss: 0.8759, LR: 0.000250
Epoch 83/100, Loss: 0.8752, LR: 0.000250
Epoch 84/100, Loss: 0.8750, LR: 0.000250
Epoch 85/100, Loss: 0.8749, LR: 0.000250
Epoch 86/100, Loss: 0.8750, LR: 0.000250
Epoch 87/100, Loss: 0.8751, LR: 0.000250
Epoch 88/100, Loss: 0.8756, LR: 0.000250
Epoch 89/100, Loss: 0.8763, LR: 0.000250
Epoch 90/100, Loss: 0.8762, LR: 0.000250
Epoch 91/100, Loss: 0.8762, LR: 0.000250
Epoch 92/100, Loss: 0.8758, LR: 0.000250
Epoch 93/100, Loss: 0.8757, LR: 0.000250
Epoch 94/100, Loss: 0.8757, LR: 0.000250
Epoch 95/100, Loss: 0.8756, LR: 0.000250
Epoch 96/100, Loss: 0.8759, LR: 0.000250
Epoch 97/100, Loss: 0.8759, LR: 0.000250
Epoch 98/100, Loss: 0.8756, LR: 0.000250
Epoch 99/100, Loss: 0.8757, LR: 0.000250
Epoch 100/100, Loss: 0.8756, LR: 0.000250
Model saved to ./model/latest.pth

Evaluate 1/100
Evaluate 2/100
Evaluate 3/100
Evaluate 4/100
Evaluate 5/100
Evaluate 6/100
Evaluate 7/100
Evaluate 8/100
Evaluate 9/100
Evaluate 10/100
Evaluate 11/100
Evaluate 12/100
Evaluate 13/100
Evaluate 14/100
Evaluate 15/100
Evaluate 16/100
Evaluate 17/100
Evaluate 18/100
Evaluate 19/100
Evaluate 20/100
Evaluate 21/100
Evaluate 22/100
Evaluate 23/100
Evaluate 24/100
Evaluate 25/100
Evaluate 26/100
Evaluate 27/100
Evaluate 28/100
Evaluate 29/100
Evaluate 30/100
Evaluate 31/100
Evaluate 32/100
Evaluate 33/100
Evaluate 34/100
Evaluate 35/100
Evaluate 36/100
Evaluate 37/100
Evaluate 38/100
Evaluate 39/100
Evaluate 40/100
Evaluate 41/100
Evaluate 42/100
Evaluate 43/100
Evaluate 44/100
Evaluate 45/100
Evaluate 46/100
Evaluate 47/100
Evaluate 48/100
Evaluate 49/100
Evaluate 50/100
Evaluate 51/100
Evaluate 52/100
Evaluate 53/100
Evaluate 54/100
Evaluate 55/100
Evaluate 56/100
Evaluate 57/100
Evaluate 58/100
Evaluate 59/100
Evaluate 60/100
Evaluate 61/100
Evaluate 62/100
Evaluate 63/100
Evaluate 64/100
Evaluate 65/100
Evaluate 66/100
Evaluate 67/100
Evaluate 68/100
Evaluate 69/100
Evaluate 70/100
Evaluate 71/100
Evaluate 72/100
Evaluate 73/100
Evaluate 74/100
Evaluate 75/100
Evaluate 76/100
Evaluate 77/100
Evaluate 78/100
Evaluate 79/100
Evaluate 80/100
Evaluate 81/100
Evaluate 82/100
Evaluate 83/100
Evaluate 84/100
Evaluate 85/100
Evaluate 86/100
Evaluate 87/100
Evaluate 88/100
Evaluate 89/100
Evaluate 90/100
Evaluate 91/100
Evaluate 92/100
Evaluate 93/100
Evaluate 94/100
Evaluate 95/100
Evaluate 96/100
Evaluate 97/100
Evaluate 98/100
Evaluate 99/100
Evaluate 100/100
AveragePoint 0.445
Change BestPlayer
>> Model updated (win rate: 44.5%)

Evaluate 1/10
Evaluate 2/10
Evaluate 3/10
Evaluate 4/10
Evaluate 5/10
Evaluate 6/10
Evaluate 7/10
Evaluate 8/10
Evaluate 9/10
Evaluate 10/10
VS_Random 0.4
>> Cycle 0 completed. Checkpoint saved.

Train 1 ====================================
>> Game Count: 500
>> MCTS Simulations: 100
>> Learning Rate: 0.001
>> Starting parallel self-play with 8 workers (C++ backend)
>> Total games: 500, Games per worker: 62
>> MCTS batch size: 32, PV evaluate count: 100
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 8: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 2: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 1: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 5: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 6: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 4: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 3: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 7: 10/62 games completed
Worker 2: 20/63 games completed
Worker 1: 20/63 games completed
Worker 8: 20/62 games completed
Worker 6: 20/62 games completed
Worker 5: 20/62 games completed
Worker 3: 20/63 games completed
Worker 4: 20/63 games completed
Worker 7: 20/62 games completed
Worker 2: 30/63 games completed
Worker 1: 30/63 games completed
Worker 5: 30/62 games completed
Worker 6: 30/62 games completed
Worker 8: 30/62 games completed
Worker 3: 30/63 games completed
Worker 4: 30/63 games completed
Worker 7: 30/62 games completed
Worker 2: 40/63 games completed
Worker 1: 40/63 games completed
Worker 5: 40/62 games completed
Worker 8: 40/62 games completed
Worker 6: 40/62 games completed
Worker 3: 40/63 games completed
Worker 4: 40/63 games completed
Worker 7: 40/62 games completed
Worker 2: 50/63 games completed
Worker 5: 50/62 games completed
Worker 1: 50/63 games completed
Worker 6: 50/62 games completed
Worker 8: 50/62 games completed
Worker 4: 50/63 games completed
Worker 3: 50/63 games completed
Worker 7: 50/62 games completed
Worker 2: 60/63 games completed
Worker 1: 60/63 games completed
Worker 5: 60/62 games completed
Worker 8: 60/62 games completed
Worker 3: 60/63 games completed
Worker 4: 60/63 games completed
Worker 6: 60/62 games completed
Worker 7: 60/62 games completed
>> Collected 24371 training samples from 500 games
>> Saved to ./data/20251030154858.history
>> Train 1
>> Learning Rate: 0.001
Epoch 1/100, Loss: 1.5376, LR: 0.001000
Epoch 2/100, Loss: 1.4212, LR: 0.001000
Epoch 3/100, Loss: 2.7110, LR: 0.001000
Epoch 4/100, Loss: 2.6724, LR: 0.001000
Epoch 5/100, Loss: 2.6591, LR: 0.001000
Epoch 6/100, Loss: 2.6502, LR: 0.001000
Epoch 7/100, Loss: 2.6438, LR: 0.001000
Epoch 8/100, Loss: 2.6384, LR: 0.001000
Epoch 9/100, Loss: 2.6368, LR: 0.001000
Epoch 10/100, Loss: 2.6347, LR: 0.001000
Epoch 11/100, Loss: 2.6325, LR: 0.001000
Epoch 12/100, Loss: 2.6327, LR: 0.001000
Epoch 13/100, Loss: 2.6330, LR: 0.001000
Epoch 14/100, Loss: 2.6464, LR: 0.001000
Epoch 15/100, Loss: 2.6477, LR: 0.001000
Epoch 16/100, Loss: 2.6434, LR: 0.001000
Epoch 17/100, Loss: 2.6354, LR: 0.001000
Epoch 18/100, Loss: 2.6291, LR: 0.001000
Epoch 19/100, Loss: 2.6269, LR: 0.001000
Epoch 20/100, Loss: 2.6266, LR: 0.001000
Epoch 21/100, Loss: 2.6281, LR: 0.001000
Epoch 22/100, Loss: 2.6294, LR: 0.001000
Epoch 23/100, Loss: 2.6307, LR: 0.001000
Epoch 24/100, Loss: 2.6282, LR: 0.001000
Epoch 25/100, Loss: 2.6281, LR: 0.001000
Epoch 26/100, Loss: 2.6432, LR: 0.001000
Epoch 27/100, Loss: 2.4202, LR: 0.001000
Epoch 28/100, Loss: 1.2638, LR: 0.001000
Epoch 29/100, Loss: 1.2762, LR: 0.001000
Epoch 30/100, Loss: 1.4715, LR: 0.001000
Epoch 31/100, Loss: 1.2583, LR: 0.001000
Epoch 32/100, Loss: 1.2978, LR: 0.001000
Epoch 33/100, Loss: 1.3978, LR: 0.001000
Epoch 34/100, Loss: 1.2129, LR: 0.001000
Epoch 35/100, Loss: 1.1413, LR: 0.001000
Epoch 36/100, Loss: 1.1366, LR: 0.001000
Epoch 37/100, Loss: 1.1435, LR: 0.001000
Epoch 38/100, Loss: 1.1479, LR: 0.001000
Epoch 39/100, Loss: 1.1563, LR: 0.001000
Epoch 40/100, Loss: 1.1231, LR: 0.001000
Epoch 41/100, Loss: 1.1208, LR: 0.001000
Epoch 42/100, Loss: 1.1229, LR: 0.001000
Epoch 43/100, Loss: 1.1273, LR: 0.001000
Epoch 44/100, Loss: 1.1164, LR: 0.001000
Epoch 45/100, Loss: 1.1102, LR: 0.001000
Epoch 46/100, Loss: 1.1688, LR: 0.001000
Epoch 47/100, Loss: 1.2023, LR: 0.001000
Epoch 48/100, Loss: 1.2392, LR: 0.001000
Epoch 49/100, Loss: 1.2986, LR: 0.001000
Epoch 50/100, Loss: 1.2653, LR: 0.000500
Epoch 51/100, Loss: 1.1715, LR: 0.000500
Epoch 52/100, Loss: 1.1239, LR: 0.000500
Epoch 53/100, Loss: 1.1219, LR: 0.000500
Epoch 54/100, Loss: 1.1132, LR: 0.000500
Epoch 55/100, Loss: 1.1149, LR: 0.000500
Epoch 56/100, Loss: 1.1098, LR: 0.000500
Epoch 57/100, Loss: 1.1091, LR: 0.000500
Epoch 58/100, Loss: 1.1088, LR: 0.000500
Epoch 59/100, Loss: 1.1089, LR: 0.000500
Epoch 60/100, Loss: 1.1075, LR: 0.000500
Epoch 61/100, Loss: 1.1080, LR: 0.000500
Epoch 62/100, Loss: 1.1079, LR: 0.000500
Epoch 63/100, Loss: 1.1088, LR: 0.000500
Epoch 64/100, Loss: 1.1088, LR: 0.000500
Epoch 65/100, Loss: 1.1082, LR: 0.000500
Epoch 66/100, Loss: 1.1078, LR: 0.000500
Epoch 67/100, Loss: 1.1076, LR: 0.000500
Epoch 68/100, Loss: 1.1096, LR: 0.000500
Epoch 69/100, Loss: 1.1073, LR: 0.000500
Epoch 70/100, Loss: 1.1080, LR: 0.000500
Epoch 71/100, Loss: 1.1080, LR: 0.000500
Epoch 72/100, Loss: 1.1082, LR: 0.000500
Epoch 73/100, Loss: 1.1079, LR: 0.000500
Epoch 74/100, Loss: 1.1078, LR: 0.000500
Epoch 75/100, Loss: 1.1070, LR: 0.000500
Epoch 76/100, Loss: 1.1073, LR: 0.000500
Epoch 77/100, Loss: 1.1084, LR: 0.000500
Epoch 78/100, Loss: 1.1073, LR: 0.000500
Epoch 79/100, Loss: 1.1085, LR: 0.000500
Epoch 80/100, Loss: 1.1143, LR: 0.000250
Epoch 81/100, Loss: 1.1115, LR: 0.000250
Epoch 82/100, Loss: 1.1076, LR: 0.000250
Epoch 83/100, Loss: 1.1066, LR: 0.000250
Epoch 84/100, Loss: 1.1056, LR: 0.000250
Epoch 85/100, Loss: 1.1053, LR: 0.000250
Epoch 86/100, Loss: 1.1056, LR: 0.000250
Epoch 87/100, Loss: 1.1061, LR: 0.000250
Epoch 88/100, Loss: 1.1053, LR: 0.000250
Epoch 89/100, Loss: 1.1055, LR: 0.000250
Epoch 90/100, Loss: 1.1050, LR: 0.000250
Epoch 91/100, Loss: 1.1057, LR: 0.000250
Epoch 92/100, Loss: 1.1094, LR: 0.000250
Epoch 93/100, Loss: 1.1073, LR: 0.000250
Epoch 94/100, Loss: 1.1071, LR: 0.000250
Epoch 95/100, Loss: 1.1061, LR: 0.000250
Epoch 96/100, Loss: 1.1053, LR: 0.000250
Epoch 97/100, Loss: 1.1057, LR: 0.000250
Epoch 98/100, Loss: 1.1058, LR: 0.000250
Epoch 99/100, Loss: 1.1058, LR: 0.000250
Epoch 100/100, Loss: 1.1053, LR: 0.000250
Model saved to ./model/latest.pth

Evaluate 1/100
Evaluate 2/100
Evaluate 3/100
Evaluate 4/100
Evaluate 5/100
Evaluate 6/100
Evaluate 7/100
Evaluate 8/100
Evaluate 9/100
Evaluate 10/100
Evaluate 11/100
Evaluate 12/100
Evaluate 13/100
Evaluate 14/100
Evaluate 15/100
Evaluate 16/100
Evaluate 17/100
Evaluate 18/100
Evaluate 19/100
Evaluate 20/100
Evaluate 21/100
Evaluate 22/100
Evaluate 23/100
Evaluate 24/100
Evaluate 25/100
Evaluate 26/100
Evaluate 27/100
Evaluate 28/100
Evaluate 29/100
Evaluate 30/100
Evaluate 31/100
Evaluate 32/100
Evaluate 33/100
Evaluate 34/100
Evaluate 35/100
Evaluate 36/100
Evaluate 37/100
Evaluate 38/100
Evaluate 39/100
Evaluate 40/100
Evaluate 41/100
Evaluate 42/100
Evaluate 43/100
Evaluate 44/100
Evaluate 45/100
Evaluate 46/100
Evaluate 47/100
Evaluate 48/100
Evaluate 49/100
Evaluate 50/100
Evaluate 51/100
Evaluate 52/100
Evaluate 53/100
Evaluate 54/100
Evaluate 55/100
Evaluate 56/100
Evaluate 57/100
Evaluate 58/100
Evaluate 59/100
Evaluate 60/100
Evaluate 61/100
Evaluate 62/100
Evaluate 63/100
Evaluate 64/100
Evaluate 65/100
Evaluate 66/100
Evaluate 67/100
Evaluate 68/100
Evaluate 69/100
Evaluate 70/100
Evaluate 71/100
Evaluate 72/100
Evaluate 73/100
Evaluate 74/100
Evaluate 75/100
Evaluate 76/100
Evaluate 77/100
Evaluate 78/100
Evaluate 79/100
Evaluate 80/100
Evaluate 81/100
Evaluate 82/100
Evaluate 83/100
Evaluate 84/100
Evaluate 85/100
Evaluate 86/100
Evaluate 87/100
Evaluate 88/100
Evaluate 89/100
Evaluate 90/100
Evaluate 91/100
Evaluate 92/100
Evaluate 93/100
Evaluate 94/100
Evaluate 95/100
Evaluate 96/100
Evaluate 97/100
Evaluate 98/100
Evaluate 99/100
Evaluate 100/100
AveragePoint 0.53
Change BestPlayer
>> Model updated (win rate: 53.0%)

Evaluate 1/10
Evaluate 2/10
Evaluate 3/10
Evaluate 4/10
Evaluate 5/10
Evaluate 6/10
Evaluate 7/10
Evaluate 8/10
Evaluate 9/10
Evaluate 10/10
VS_Random 0.15
>> Cycle 1 completed. Checkpoint saved.

Train 2 ====================================
>> Game Count: 500
>> MCTS Simulations: 100
>> Learning Rate: 0.001
>> Starting parallel self-play with 8 workers (C++ backend)
>> Total games: 500, Games per worker: 62
>> MCTS batch size: 32, PV evaluate count: 100
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 8: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 6: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 1: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 3: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 7: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 4: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 2: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 5: 10/62 games completed
Worker 6: 20/62 games completed
Worker 3: 20/63 games completed
Worker 5: 20/62 games completed
Worker 1: 20/63 games completed
Worker 7: 20/62 games completed
Worker 8: 20/62 games completed
Worker 2: 20/63 games completed
Worker 4: 20/63 games completed
Worker 3: 30/63 games completed
Worker 6: 30/62 games completed
Worker 1: 30/63 games completed
Worker 8: 30/62 games completed
Worker 5: 30/62 games completed
Worker 7: 30/62 games completed
Worker 2: 30/63 games completed
Worker 4: 30/63 games completed
Worker 3: 40/63 games completed
Worker 1: 40/63 games completed
Worker 6: 40/62 games completed
Worker 5: 40/62 games completed
Worker 8: 40/62 games completed
Worker 7: 40/62 games completed
Worker 2: 40/63 games completed
Worker 4: 40/63 games completed
Worker 1: 50/63 games completed
Worker 3: 50/63 games completed
Worker 8: 50/62 games completed
Worker 6: 50/62 games completed
Worker 5: 50/62 games completed
Worker 7: 50/62 games completed
Worker 4: 50/63 games completed
Worker 2: 50/63 games completed
Worker 1: 60/63 games completed
Worker 3: 60/63 games completed
Worker 6: 60/62 games completed
Worker 8: 60/62 games completed
Worker 5: 60/62 games completed
Worker 7: 60/62 games completed
Worker 4: 60/63 games completed
Worker 2: 60/63 games completed
>> Collected 24142 training samples from 500 games
>> Saved to ./data/20251030160133.history
>> Train 2
>> Learning Rate: 0.001
Epoch 1/100, Loss: 1.0847, LR: 0.001000
Epoch 2/100, Loss: 1.0333, LR: 0.001000
Epoch 3/100, Loss: 1.0336, LR: 0.001000
Epoch 4/100, Loss: 1.0902, LR: 0.001000
Epoch 5/100, Loss: 1.0039, LR: 0.001000
Epoch 6/100, Loss: 1.0346, LR: 0.001000
Epoch 7/100, Loss: 1.0338, LR: 0.001000
Epoch 8/100, Loss: 1.0190, LR: 0.001000
Epoch 9/100, Loss: 1.0041, LR: 0.001000
Epoch 10/100, Loss: 0.9980, LR: 0.001000
Epoch 11/100, Loss: 0.9962, LR: 0.001000
Epoch 12/100, Loss: 0.9945, LR: 0.001000
Epoch 13/100, Loss: 1.0497, LR: 0.001000
Epoch 14/100, Loss: 1.1297, LR: 0.001000
Epoch 15/100, Loss: 1.0428, LR: 0.001000
Epoch 16/100, Loss: 1.0336, LR: 0.001000
Epoch 17/100, Loss: 1.0316, LR: 0.001000
Epoch 18/100, Loss: 1.0172, LR: 0.001000
Epoch 19/100, Loss: 0.9938, LR: 0.001000
Epoch 20/100, Loss: 0.9860, LR: 0.001000
Epoch 21/100, Loss: 0.9836, LR: 0.001000
Epoch 22/100, Loss: 0.9835, LR: 0.001000
Epoch 23/100, Loss: 0.9830, LR: 0.001000
Epoch 24/100, Loss: 0.9823, LR: 0.001000
Epoch 25/100, Loss: 0.9829, LR: 0.001000
Epoch 26/100, Loss: 0.9829, LR: 0.001000
Epoch 27/100, Loss: 0.9829, LR: 0.001000
Epoch 28/100, Loss: 0.9823, LR: 0.001000
Epoch 29/100, Loss: 0.9826, LR: 0.001000
Epoch 30/100, Loss: 0.9833, LR: 0.001000
Epoch 31/100, Loss: 0.9890, LR: 0.001000
Epoch 32/100, Loss: 1.0023, LR: 0.001000
Epoch 33/100, Loss: 0.9963, LR: 0.001000
Epoch 34/100, Loss: 0.9866, LR: 0.001000
Epoch 35/100, Loss: 0.9859, LR: 0.001000
Epoch 36/100, Loss: 0.9828, LR: 0.001000
Epoch 37/100, Loss: 0.9810, LR: 0.001000
Epoch 38/100, Loss: 0.9806, LR: 0.001000
Epoch 39/100, Loss: 0.9802, LR: 0.001000
Epoch 40/100, Loss: 0.9802, LR: 0.001000
Epoch 41/100, Loss: 0.9804, LR: 0.001000
Epoch 42/100, Loss: 0.9808, LR: 0.001000
Epoch 43/100, Loss: 0.9807, LR: 0.001000
Epoch 44/100, Loss: 0.9801, LR: 0.001000
Epoch 45/100, Loss: 0.9804, LR: 0.001000
Epoch 46/100, Loss: 0.9817, LR: 0.001000
Epoch 47/100, Loss: 0.9827, LR: 0.001000
Epoch 48/100, Loss: 0.9823, LR: 0.001000
Epoch 49/100, Loss: 0.9833, LR: 0.001000
Epoch 50/100, Loss: 1.0061, LR: 0.000500
Epoch 51/100, Loss: 0.9875, LR: 0.000500
Epoch 52/100, Loss: 0.9821, LR: 0.000500
Epoch 53/100, Loss: 0.9809, LR: 0.000500
Epoch 54/100, Loss: 0.9804, LR: 0.000500
Epoch 55/100, Loss: 0.9799, LR: 0.000500
Epoch 56/100, Loss: 0.9808, LR: 0.000500
Epoch 57/100, Loss: 0.9797, LR: 0.000500
Epoch 58/100, Loss: 0.9799, LR: 0.000500
Epoch 59/100, Loss: 0.9791, LR: 0.000500
Epoch 60/100, Loss: 0.9793, LR: 0.000500
Epoch 61/100, Loss: 0.9793, LR: 0.000500
Epoch 62/100, Loss: 0.9793, LR: 0.000500
Epoch 63/100, Loss: 0.9793, LR: 0.000500
Epoch 64/100, Loss: 0.9791, LR: 0.000500
Epoch 65/100, Loss: 0.9794, LR: 0.000500
Epoch 66/100, Loss: 0.9797, LR: 0.000500
Epoch 67/100, Loss: 0.9797, LR: 0.000500
Epoch 68/100, Loss: 0.9799, LR: 0.000500
Epoch 69/100, Loss: 0.9797, LR: 0.000500
Epoch 70/100, Loss: 0.9793, LR: 0.000500
Epoch 71/100, Loss: 0.9797, LR: 0.000500
Epoch 72/100, Loss: 0.9798, LR: 0.000500
Epoch 73/100, Loss: 0.9839, LR: 0.000500
Epoch 74/100, Loss: 0.9832, LR: 0.000500
Epoch 75/100, Loss: 0.9815, LR: 0.000500
Epoch 76/100, Loss: 0.9811, LR: 0.000500
Epoch 77/100, Loss: 0.9808, LR: 0.000500
Epoch 78/100, Loss: 0.9804, LR: 0.000500
Epoch 79/100, Loss: 0.9807, LR: 0.000500
Epoch 80/100, Loss: 0.9809, LR: 0.000250
Epoch 81/100, Loss: 0.9799, LR: 0.000250
Epoch 82/100, Loss: 0.9802, LR: 0.000250
Epoch 83/100, Loss: 0.9800, LR: 0.000250
Epoch 84/100, Loss: 0.9805, LR: 0.000250
Epoch 85/100, Loss: 0.9802, LR: 0.000250
Epoch 86/100, Loss: 0.9798, LR: 0.000250
Epoch 87/100, Loss: 0.9802, LR: 0.000250
Epoch 88/100, Loss: 0.9803, LR: 0.000250
Epoch 89/100, Loss: 0.9801, LR: 0.000250
Epoch 90/100, Loss: 0.9801, LR: 0.000250
Epoch 91/100, Loss: 0.9803, LR: 0.000250
Epoch 92/100, Loss: 0.9804, LR: 0.000250
Epoch 93/100, Loss: 0.9803, LR: 0.000250
Epoch 94/100, Loss: 0.9804, LR: 0.000250
Epoch 95/100, Loss: 0.9804, LR: 0.000250
Epoch 96/100, Loss: 0.9802, LR: 0.000250
Epoch 97/100, Loss: 0.9805, LR: 0.000250
Epoch 98/100, Loss: 0.9804, LR: 0.000250
Epoch 99/100, Loss: 0.9805, LR: 0.000250
Epoch 100/100, Loss: 0.9802, LR: 0.000250
Model saved to ./model/latest.pth

Evaluate 1/100
Evaluate 2/100
Evaluate 3/100
Evaluate 4/100
Evaluate 5/100
Evaluate 6/100
Evaluate 7/100
Evaluate 8/100
Evaluate 9/100
Evaluate 10/100
Evaluate 11/100
Evaluate 12/100
Evaluate 13/100
Evaluate 14/100
Evaluate 15/100
Evaluate 16/100
Evaluate 17/100
Evaluate 18/100
Evaluate 19/100
Evaluate 20/100
Evaluate 21/100
Evaluate 22/100
Evaluate 23/100
Evaluate 24/100
Evaluate 25/100
Evaluate 26/100
Evaluate 27/100
Evaluate 28/100
Evaluate 29/100
Evaluate 30/100
Evaluate 31/100
Evaluate 32/100
Evaluate 33/100
Evaluate 34/100
Evaluate 35/100
Evaluate 36/100
Evaluate 37/100
Evaluate 38/100
Evaluate 39/100
Evaluate 40/100
Evaluate 41/100
Evaluate 42/100
Evaluate 43/100
Evaluate 44/100
Evaluate 45/100
Evaluate 46/100
Evaluate 47/100
Evaluate 48/100
Evaluate 49/100
Evaluate 50/100
Evaluate 51/100
Evaluate 52/100
Evaluate 53/100
Evaluate 54/100
Evaluate 55/100
Evaluate 56/100
Evaluate 57/100
Evaluate 58/100
Evaluate 59/100
Evaluate 60/100
Evaluate 61/100
Evaluate 62/100
Evaluate 63/100
Evaluate 64/100
Evaluate 65/100
Evaluate 66/100
Evaluate 67/100
Evaluate 68/100
Evaluate 69/100
Evaluate 70/100
Evaluate 71/100
Evaluate 72/100
Evaluate 73/100
Evaluate 74/100
Evaluate 75/100
Evaluate 76/100
Evaluate 77/100
Evaluate 78/100
Evaluate 79/100
Evaluate 80/100
Evaluate 81/100
Evaluate 82/100
Evaluate 83/100
Evaluate 84/100
Evaluate 85/100
Evaluate 86/100
Evaluate 87/100
Evaluate 88/100
Evaluate 89/100
Evaluate 90/100
Evaluate 91/100
Evaluate 92/100
Evaluate 93/100
Evaluate 94/100
Evaluate 95/100
Evaluate 96/100
Evaluate 97/100
Evaluate 98/100
Evaluate 99/100
Evaluate 100/100
AveragePoint 0.5
Change BestPlayer
>> Model updated (win rate: 50.0%)

Evaluate 1/10
Evaluate 2/10
Evaluate 3/10
Evaluate 4/10
Evaluate 5/10
Evaluate 6/10
Evaluate 7/10
Evaluate 8/10
Evaluate 9/10
Evaluate 10/10
VS_Random 0.7
>> Cycle 2 completed. Checkpoint saved.

Train 3 ====================================
>> Game Count: 500
>> MCTS Simulations: 100
>> Learning Rate: 0.001
>> Starting parallel self-play with 8 workers (C++ backend)
>> Total games: 500, Games per worker: 62
>> MCTS batch size: 32, PV evaluate count: 100
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 1: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 2: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 6: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 5: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 3: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 7: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 4: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 8: 10/62 games completed
Worker 2: 20/63 games completed
Worker 1: 20/63 games completed
Worker 6: 20/62 games completed
Worker 3: 20/63 games completed
Worker 5: 20/62 games completed
Worker 7: 20/62 games completed
Worker 4: 20/63 games completed
Worker 8: 20/62 games completed
Worker 6: 30/62 games completed
Worker 2: 30/63 games completed
Worker 1: 30/63 games completed
Worker 7: 30/62 games completed
Worker 5: 30/62 games completed
Worker 3: 30/63 games completed
Worker 4: 30/63 games completed
Worker 8: 30/62 games completed
Worker 2: 40/63 games completed
Worker 1: 40/63 games completed
Worker 6: 40/62 games completed
Worker 7: 40/62 games completed
Worker 3: 40/63 games completed
Worker 5: 40/62 games completed
Worker 4: 40/63 games completed
Worker 8: 40/62 games completed
Worker 2: 50/63 games completed
Worker 1: 50/63 games completed
Worker 6: 50/62 games completed
Worker 7: 50/62 games completed
Worker 3: 50/63 games completed
Worker 4: 50/63 games completed
Worker 5: 50/62 games completed
Worker 2: 60/63 games completed
Worker 8: 50/62 games completed
Worker 6: 60/62 games completed
Worker 1: 60/63 games completed
Worker 7: 60/62 games completed
Worker 3: 60/63 games completed
Worker 4: 60/63 games completed
Worker 5: 60/62 games completed
Worker 8: 60/62 games completed
>> Collected 24066 training samples from 500 games
>> Saved to ./data/20251030161357.history
>> Train 3
>> Learning Rate: 0.001
Epoch 1/100, Loss: 1.1260, LR: 0.001000
Epoch 2/100, Loss: 1.1032, LR: 0.001000
Epoch 3/100, Loss: 1.0907, LR: 0.001000
Epoch 4/100, Loss: 1.0803, LR: 0.001000
Epoch 5/100, Loss: 1.0831, LR: 0.001000
Epoch 6/100, Loss: 1.0761, LR: 0.001000
Epoch 7/100, Loss: 1.0738, LR: 0.001000
Epoch 8/100, Loss: 1.1139, LR: 0.001000
Epoch 9/100, Loss: 1.0935, LR: 0.001000
Epoch 10/100, Loss: 1.0970, LR: 0.001000
Epoch 11/100, Loss: 1.0863, LR: 0.001000
Epoch 12/100, Loss: 1.0757, LR: 0.001000
Epoch 13/100, Loss: 1.0844, LR: 0.001000
Epoch 14/100, Loss: 1.0738, LR: 0.001000
Epoch 15/100, Loss: 1.0648, LR: 0.001000
Epoch 16/100, Loss: 1.0650, LR: 0.001000
Epoch 17/100, Loss: 1.0811, LR: 0.001000
Epoch 18/100, Loss: 1.1373, LR: 0.001000
Epoch 19/100, Loss: 1.0814, LR: 0.001000
Epoch 20/100, Loss: 1.0977, LR: 0.001000
Epoch 21/100, Loss: 1.0801, LR: 0.001000
Epoch 22/100, Loss: 1.2509, LR: 0.001000
Epoch 23/100, Loss: 1.1813, LR: 0.001000
Epoch 24/100, Loss: 1.1496, LR: 0.001000
Epoch 25/100, Loss: 1.1296, LR: 0.001000
Epoch 26/100, Loss: 1.1295, LR: 0.001000
Epoch 27/100, Loss: 1.0599, LR: 0.001000
Epoch 28/100, Loss: 1.0488, LR: 0.001000
Epoch 29/100, Loss: 1.0494, LR: 0.001000
Epoch 30/100, Loss: 1.0441, LR: 0.001000
Epoch 31/100, Loss: 1.0609, LR: 0.001000
Epoch 32/100, Loss: 1.1585, LR: 0.001000
Epoch 33/100, Loss: 1.1682, LR: 0.001000
Epoch 34/100, Loss: 1.2064, LR: 0.001000
Epoch 35/100, Loss: 1.1413, LR: 0.001000
Epoch 36/100, Loss: 1.1371, LR: 0.001000
Epoch 37/100, Loss: 1.1983, LR: 0.001000
Epoch 38/100, Loss: 1.2411, LR: 0.001000
Epoch 39/100, Loss: 1.2288, LR: 0.001000
Epoch 40/100, Loss: 1.2183, LR: 0.001000
Epoch 41/100, Loss: 1.1783, LR: 0.001000
Epoch 42/100, Loss: 1.1691, LR: 0.001000
Epoch 43/100, Loss: 1.1637, LR: 0.001000
Epoch 44/100, Loss: 1.1397, LR: 0.001000
Epoch 45/100, Loss: 1.1419, LR: 0.001000
Epoch 46/100, Loss: 1.1410, LR: 0.001000
Epoch 47/100, Loss: 1.1394, LR: 0.001000
Epoch 48/100, Loss: 1.1391, LR: 0.001000
Epoch 49/100, Loss: 1.1622, LR: 0.001000
Epoch 50/100, Loss: 1.1550, LR: 0.000500
Epoch 51/100, Loss: 1.1208, LR: 0.000500
Epoch 52/100, Loss: 1.0787, LR: 0.000500
Epoch 53/100, Loss: 1.0571, LR: 0.000500
Epoch 54/100, Loss: 1.0621, LR: 0.000500
Epoch 55/100, Loss: 1.0770, LR: 0.000500
Epoch 56/100, Loss: 1.0462, LR: 0.000500
Epoch 57/100, Loss: 1.0354, LR: 0.000500
Epoch 58/100, Loss: 1.0691, LR: 0.000500
Epoch 59/100, Loss: 1.0213, LR: 0.000500
Epoch 60/100, Loss: 1.0117, LR: 0.000500
Epoch 61/100, Loss: 1.0182, LR: 0.000500
Epoch 62/100, Loss: 1.0168, LR: 0.000500
Epoch 63/100, Loss: 1.0043, LR: 0.000500
Epoch 64/100, Loss: 0.9988, LR: 0.000500
Epoch 65/100, Loss: 1.0376, LR: 0.000500
Epoch 66/100, Loss: 1.0203, LR: 0.000500
Epoch 67/100, Loss: 1.0096, LR: 0.000500
Epoch 68/100, Loss: 1.0110, LR: 0.000500
Epoch 69/100, Loss: 1.0131, LR: 0.000500
Epoch 70/100, Loss: 1.0147, LR: 0.000500
Epoch 71/100, Loss: 1.0026, LR: 0.000500
Epoch 72/100, Loss: 0.9935, LR: 0.000500
Epoch 73/100, Loss: 0.9827, LR: 0.000500
Epoch 74/100, Loss: 0.9946, LR: 0.000500
Epoch 75/100, Loss: 0.9805, LR: 0.000500
Epoch 76/100, Loss: 0.9826, LR: 0.000500
Epoch 77/100, Loss: 0.9715, LR: 0.000500
Epoch 78/100, Loss: 0.9672, LR: 0.000500
Epoch 79/100, Loss: 0.9738, LR: 0.000500
Epoch 80/100, Loss: 0.9763, LR: 0.000250
Epoch 81/100, Loss: 0.9777, LR: 0.000250
Epoch 82/100, Loss: 0.9697, LR: 0.000250
Epoch 83/100, Loss: 0.9639, LR: 0.000250
Epoch 84/100, Loss: 0.9689, LR: 0.000250
Epoch 85/100, Loss: 0.9658, LR: 0.000250
Epoch 86/100, Loss: 0.9629, LR: 0.000250
Epoch 87/100, Loss: 0.9565, LR: 0.000250
Epoch 88/100, Loss: 0.9594, LR: 0.000250
Epoch 89/100, Loss: 0.9552, LR: 0.000250
Epoch 90/100, Loss: 0.9579, LR: 0.000250
Epoch 91/100, Loss: 0.9640, LR: 0.000250
Epoch 92/100, Loss: 0.9524, LR: 0.000250
Epoch 93/100, Loss: 0.9523, LR: 0.000250
Epoch 94/100, Loss: 0.9523, LR: 0.000250
Epoch 95/100, Loss: 0.9474, LR: 0.000250
Epoch 96/100, Loss: 0.9517, LR: 0.000250
Epoch 97/100, Loss: 0.9492, LR: 0.000250
Epoch 98/100, Loss: 0.9542, LR: 0.000250
Epoch 99/100, Loss: 0.9545, LR: 0.000250
Epoch 100/100, Loss: 0.9495, LR: 0.000250
Model saved to ./model/latest.pth

Evaluate 1/100
Evaluate 2/100
Evaluate 3/100
Evaluate 4/100
Evaluate 5/100
Evaluate 6/100
Evaluate 7/100
Evaluate 8/100
Evaluate 9/100
Evaluate 10/100
Evaluate 11/100
Evaluate 12/100
Evaluate 13/100
Evaluate 14/100
Evaluate 15/100
Evaluate 16/100
Evaluate 17/100
Evaluate 18/100
Evaluate 19/100
Evaluate 20/100
Evaluate 21/100
Evaluate 22/100
Evaluate 23/100
Evaluate 24/100
Evaluate 25/100
Evaluate 26/100
Evaluate 27/100
Evaluate 28/100
Evaluate 29/100
Evaluate 30/100
Evaluate 31/100
Evaluate 32/100
Evaluate 33/100
Evaluate 34/100
Evaluate 35/100
Evaluate 36/100
Evaluate 37/100
Evaluate 38/100
Evaluate 39/100
Evaluate 40/100
Evaluate 41/100
Evaluate 42/100
Evaluate 43/100
Evaluate 44/100
Evaluate 45/100
Evaluate 46/100
Evaluate 47/100
Evaluate 48/100
Evaluate 49/100
Evaluate 50/100
Evaluate 51/100
Evaluate 52/100
Evaluate 53/100
Evaluate 54/100
Evaluate 55/100
Evaluate 56/100
Evaluate 57/100
Evaluate 58/100
Evaluate 59/100
Evaluate 60/100
Evaluate 61/100
Evaluate 62/100
Evaluate 63/100
Evaluate 64/100
Evaluate 65/100
Evaluate 66/100
Evaluate 67/100
Evaluate 68/100
Evaluate 69/100
Evaluate 70/100
Evaluate 71/100
Evaluate 72/100
Evaluate 73/100
Evaluate 74/100
Evaluate 75/100
Evaluate 76/100
Evaluate 77/100
Evaluate 78/100
Evaluate 79/100
Evaluate 80/100
Evaluate 81/100
Evaluate 82/100
Evaluate 83/100
Evaluate 84/100
Evaluate 85/100
Evaluate 86/100
Evaluate 87/100
Evaluate 88/100
Evaluate 89/100
Evaluate 90/100
Evaluate 91/100
Evaluate 92/100
Evaluate 93/100
Evaluate 94/100
Evaluate 95/100
Evaluate 96/100
Evaluate 97/100
Evaluate 98/100
Evaluate 99/100
Evaluate 100/100
AveragePoint 0.535
Change BestPlayer
>> Model updated (win rate: 53.5%)

Evaluate 1/10
Evaluate 2/10
Evaluate 3/10
Evaluate 4/10
Evaluate 5/10
Evaluate 6/10
Evaluate 7/10
Evaluate 8/10
Evaluate 9/10
Evaluate 10/10
VS_Random 0.35
>> Cycle 3 completed. Checkpoint saved.

Train 4 ====================================
>> Game Count: 500
>> MCTS Simulations: 100
>> Learning Rate: 0.001
>> Starting parallel self-play with 8 workers (C++ backend)
>> Total games: 500, Games per worker: 62
>> MCTS batch size: 32, PV evaluate count: 100
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 1: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 7: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 5: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 6: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 8: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 2: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 3: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 4: 10/63 games completed
Worker 8: 20/62 games completed
Worker 1: 20/63 games completed
Worker 7: 20/62 games completed
Worker 5: 20/62 games completed
Worker 2: 20/63 games completed
Worker 6: 20/62 games completed
Worker 3: 20/63 games completed
Worker 4: 20/63 games completed
Worker 8: 30/62 games completed
Worker 5: 30/62 games completed
Worker 7: 30/62 games completed
Worker 1: 30/63 games completed
Worker 6: 30/62 games completed
Worker 2: 30/63 games completed
Worker 3: 30/63 games completed
Worker 4: 30/63 games completed
Worker 8: 40/62 games completed
Worker 5: 40/62 games completed
Worker 7: 40/62 games completed
Worker 1: 40/63 games completed
Worker 2: 40/63 games completed
Worker 6: 40/62 games completed
Worker 3: 40/63 games completed
Worker 4: 40/63 games completed
Worker 8: 50/62 games completed
Worker 5: 50/62 games completed
Worker 1: 50/63 games completed
Worker 2: 50/63 games completed
Worker 7: 50/62 games completed
Worker 6: 50/62 games completed
Worker 3: 50/63 games completed
Worker 4: 50/63 games completed
Worker 2: 60/63 games completed
Worker 1: 60/63 games completed
Worker 8: 60/62 games completed
Worker 5: 60/62 games completed
Worker 7: 60/62 games completed
Worker 6: 60/62 games completed
Worker 3: 60/63 games completed
Worker 4: 60/63 games completed
>> Collected 24131 training samples from 500 games
>> Saved to ./data/20251030162622.history
>> Train 4
>> Learning Rate: 0.001
Epoch 1/100, Loss: 0.9927, LR: 0.001000
Epoch 2/100, Loss: 0.9530, LR: 0.001000
Epoch 3/100, Loss: 0.9466, LR: 0.001000
Epoch 4/100, Loss: 0.9370, LR: 0.001000
Epoch 5/100, Loss: 0.9723, LR: 0.001000
Epoch 6/100, Loss: 0.9322, LR: 0.001000
Epoch 7/100, Loss: 0.9311, LR: 0.001000
Epoch 8/100, Loss: 0.9267, LR: 0.001000
Epoch 9/100, Loss: 0.9264, LR: 0.001000
Epoch 10/100, Loss: 0.9500, LR: 0.001000
Epoch 11/100, Loss: 1.0759, LR: 0.001000
Epoch 12/100, Loss: 1.0018, LR: 0.001000
Epoch 13/100, Loss: 0.9940, LR: 0.001000
Epoch 14/100, Loss: 0.9278, LR: 0.001000
Epoch 15/100, Loss: 0.9245, LR: 0.001000
Epoch 16/100, Loss: 0.9400, LR: 0.001000
Epoch 17/100, Loss: 0.9239, LR: 0.001000
Epoch 18/100, Loss: 0.9228, LR: 0.001000
Epoch 19/100, Loss: 0.9216, LR: 0.001000
Epoch 20/100, Loss: 0.9211, LR: 0.001000
Epoch 21/100, Loss: 0.9204, LR: 0.001000
Epoch 22/100, Loss: 0.9208, LR: 0.001000
Epoch 23/100, Loss: 0.9203, LR: 0.001000
Epoch 24/100, Loss: 0.9202, LR: 0.001000
Epoch 25/100, Loss: 0.9202, LR: 0.001000
Epoch 26/100, Loss: 0.9197, LR: 0.001000
Epoch 27/100, Loss: 0.9196, LR: 0.001000
Epoch 28/100, Loss: 0.9213, LR: 0.001000
Epoch 29/100, Loss: 0.9287, LR: 0.001000
Epoch 30/100, Loss: 0.9260, LR: 0.001000
Epoch 31/100, Loss: 0.9295, LR: 0.001000
Epoch 32/100, Loss: 0.9219, LR: 0.001000
Epoch 33/100, Loss: 0.9205, LR: 0.001000
Epoch 34/100, Loss: 0.9196, LR: 0.001000
Epoch 35/100, Loss: 0.9190, LR: 0.001000
Epoch 36/100, Loss: 0.9191, LR: 0.001000
Epoch 37/100, Loss: 0.9183, LR: 0.001000
Epoch 38/100, Loss: 0.9184, LR: 0.001000
Epoch 39/100, Loss: 0.9204, LR: 0.001000
Epoch 40/100, Loss: 0.9193, LR: 0.001000
Epoch 41/100, Loss: 0.9204, LR: 0.001000
Epoch 42/100, Loss: 0.9203, LR: 0.001000
Epoch 43/100, Loss: 0.9209, LR: 0.001000
Epoch 44/100, Loss: 0.9193, LR: 0.001000
Epoch 45/100, Loss: 0.9192, LR: 0.001000
Epoch 46/100, Loss: 0.9186, LR: 0.001000
Epoch 47/100, Loss: 0.9190, LR: 0.001000
Epoch 48/100, Loss: 0.9189, LR: 0.001000
Epoch 49/100, Loss: 0.9195, LR: 0.001000
Epoch 50/100, Loss: 0.9321, LR: 0.000500
Epoch 51/100, Loss: 0.9259, LR: 0.000500
Epoch 52/100, Loss: 0.9180, LR: 0.000500
Epoch 53/100, Loss: 0.9172, LR: 0.000500
Epoch 54/100, Loss: 0.9163, LR: 0.000500
Epoch 55/100, Loss: 0.9159, LR: 0.000500
Epoch 56/100, Loss: 0.9162, LR: 0.000500
Epoch 57/100, Loss: 0.9156, LR: 0.000500
Epoch 58/100, Loss: 0.9155, LR: 0.000500
Epoch 59/100, Loss: 0.9155, LR: 0.000500
Epoch 60/100, Loss: 0.9152, LR: 0.000500
Epoch 61/100, Loss: 0.9152, LR: 0.000500
Epoch 62/100, Loss: 0.9154, LR: 0.000500
Epoch 63/100, Loss: 0.9151, LR: 0.000500
Epoch 64/100, Loss: 0.9155, LR: 0.000500
Epoch 65/100, Loss: 0.9155, LR: 0.000500
Epoch 66/100, Loss: 0.9155, LR: 0.000500
Epoch 67/100, Loss: 0.9150, LR: 0.000500
Epoch 68/100, Loss: 0.9156, LR: 0.000500
Epoch 69/100, Loss: 0.9157, LR: 0.000500
Epoch 70/100, Loss: 0.9155, LR: 0.000500
Epoch 71/100, Loss: 0.9155, LR: 0.000500
Epoch 72/100, Loss: 0.9169, LR: 0.000500
Epoch 73/100, Loss: 0.9168, LR: 0.000500
Epoch 74/100, Loss: 0.9157, LR: 0.000500
Epoch 75/100, Loss: 0.9154, LR: 0.000500
Epoch 76/100, Loss: 0.9164, LR: 0.000500
Epoch 77/100, Loss: 0.9158, LR: 0.000500
Epoch 78/100, Loss: 0.9150, LR: 0.000500
Epoch 79/100, Loss: 0.9149, LR: 0.000500
Epoch 80/100, Loss: 0.9152, LR: 0.000250
Epoch 81/100, Loss: 0.9153, LR: 0.000250
Epoch 82/100, Loss: 0.9147, LR: 0.000250
Epoch 83/100, Loss: 0.9149, LR: 0.000250
Epoch 84/100, Loss: 0.9171, LR: 0.000250
Epoch 85/100, Loss: 0.9236, LR: 0.000250
Epoch 86/100, Loss: 0.9206, LR: 0.000250
Epoch 87/100, Loss: 0.9190, LR: 0.000250
Epoch 88/100, Loss: 0.9154, LR: 0.000250
Epoch 89/100, Loss: 0.9153, LR: 0.000250
Epoch 90/100, Loss: 0.9152, LR: 0.000250
Epoch 91/100, Loss: 0.9148, LR: 0.000250
Epoch 92/100, Loss: 0.9151, LR: 0.000250
Epoch 93/100, Loss: 0.9146, LR: 0.000250
Epoch 94/100, Loss: 0.9149, LR: 0.000250
Epoch 95/100, Loss: 0.9148, LR: 0.000250
Epoch 96/100, Loss: 0.9146, LR: 0.000250
Epoch 97/100, Loss: 0.9149, LR: 0.000250
Epoch 98/100, Loss: 0.9151, LR: 0.000250
Epoch 99/100, Loss: 0.9150, LR: 0.000250
Epoch 100/100, Loss: 0.9148, LR: 0.000250
Model saved to ./model/latest.pth

Evaluate 1/100
Evaluate 2/100
Evaluate 3/100
Evaluate 4/100
Evaluate 5/100
Evaluate 6/100
Evaluate 7/100
Evaluate 8/100
Evaluate 9/100
Evaluate 10/100
Evaluate 11/100
Evaluate 12/100
Evaluate 13/100
Evaluate 14/100
Evaluate 15/100
Evaluate 16/100
Evaluate 17/100
Evaluate 18/100
Evaluate 19/100
Evaluate 20/100
Evaluate 21/100
Evaluate 22/100
Evaluate 23/100
Evaluate 24/100
Evaluate 25/100
Evaluate 26/100
Evaluate 27/100
Evaluate 28/100
Evaluate 29/100
Evaluate 30/100
Evaluate 31/100
Evaluate 32/100
Evaluate 33/100
Evaluate 34/100
Evaluate 35/100
Evaluate 36/100
Evaluate 37/100
Evaluate 38/100
Evaluate 39/100
Evaluate 40/100
Evaluate 41/100
Evaluate 42/100
Evaluate 43/100
Evaluate 44/100
Evaluate 45/100
Evaluate 46/100
Evaluate 47/100
Evaluate 48/100
Evaluate 49/100
Evaluate 50/100
Evaluate 51/100
Evaluate 52/100
Evaluate 53/100
Evaluate 54/100
Evaluate 55/100
Evaluate 56/100
Evaluate 57/100
Evaluate 58/100
Evaluate 59/100
Evaluate 60/100
Evaluate 61/100
Evaluate 62/100
Evaluate 63/100
Evaluate 64/100
Evaluate 65/100
Evaluate 66/100
Evaluate 67/100
Evaluate 68/100
Evaluate 69/100
Evaluate 70/100
Evaluate 71/100
Evaluate 72/100
Evaluate 73/100
Evaluate 74/100
Evaluate 75/100
Evaluate 76/100
Evaluate 77/100
Evaluate 78/100
Evaluate 79/100
Evaluate 80/100
Evaluate 81/100
Evaluate 82/100
Evaluate 83/100
Evaluate 84/100
Evaluate 85/100
Evaluate 86/100
Evaluate 87/100
Evaluate 88/100
Evaluate 89/100
Evaluate 90/100
Evaluate 91/100
Evaluate 92/100
Evaluate 93/100
Evaluate 94/100
Evaluate 95/100
Evaluate 96/100
Evaluate 97/100
Evaluate 98/100
Evaluate 99/100
Evaluate 100/100
AveragePoint 0.585
Change BestPlayer
>> Model updated (win rate: 58.5%)

Evaluate 1/10
Evaluate 2/10
Evaluate 3/10
Evaluate 4/10
Evaluate 5/10
Evaluate 6/10
Evaluate 7/10
Evaluate 8/10
Evaluate 9/10
Evaluate 10/10
VS_Random 0.4
>> Cycle 4 completed. Checkpoint saved.

Train 5 ====================================
>> Game Count: 500
>> MCTS Simulations: 100
>> Learning Rate: 0.001
>> Starting parallel self-play with 8 workers (C++ backend)
>> Total games: 500, Games per worker: 62
>> MCTS batch size: 32, PV evaluate count: 100
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 1: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 2: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 5: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 6: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 3: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 7: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 8: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 4: 10/63 games completed
Worker 2: 20/63 games completed
Worker 5: 20/62 games completed
Worker 1: 20/63 games completed
Worker 7: 20/62 games completed
Worker 4: 20/63 games completed
Worker 6: 20/62 games completed
Worker 8: 20/62 games completed
Worker 3: 20/63 games completed
Worker 2: 30/63 games completed
Worker 1: 30/63 games completed
Worker 5: 30/62 games completed
Worker 7: 30/62 games completed
Worker 6: 30/62 games completed
Worker 3: 30/63 games completed
Worker 4: 30/63 games completed
Worker 8: 30/62 games completed
Worker 2: 40/63 games completed
Worker 5: 40/62 games completed
Worker 7: 40/62 games completed
Worker 1: 40/63 games completed
Worker 3: 40/63 games completed
Worker 6: 40/62 games completed
Worker 4: 40/63 games completed
Worker 8: 40/62 games completed
Worker 2: 50/63 games completed
Worker 7: 50/62 games completed
Worker 1: 50/63 games completed
Worker 5: 50/62 games completed
Worker 3: 50/63 games completed
Worker 6: 50/62 games completed
Worker 4: 50/63 games completed
Worker 8: 50/62 games completed
Worker 2: 60/63 games completed
Worker 3: 60/63 games completed
Worker 5: 60/62 games completed
Worker 7: 60/62 games completed
Worker 1: 60/63 games completed
Worker 6: 60/62 games completed
Worker 4: 60/63 games completed
Worker 8: 60/62 games completed
>> Collected 23775 training samples from 500 games
>> Saved to ./data/20251030163826.history
>> Train 5
>> Learning Rate: 0.001
Epoch 1/100, Loss: 0.9526, LR: 0.001000
Epoch 2/100, Loss: 0.9288, LR: 0.001000
Epoch 3/100, Loss: 0.9222, LR: 0.001000
Epoch 4/100, Loss: 0.9183, LR: 0.001000
Epoch 5/100, Loss: 0.9157, LR: 0.001000
Epoch 6/100, Loss: 0.9139, LR: 0.001000
Epoch 7/100, Loss: 0.9133, LR: 0.001000
Epoch 8/100, Loss: 0.9126, LR: 0.001000
Epoch 9/100, Loss: 0.9117, LR: 0.001000
Epoch 10/100, Loss: 0.9115, LR: 0.001000
Epoch 11/100, Loss: 0.9114, LR: 0.001000
Epoch 12/100, Loss: 0.9117, LR: 0.001000
Epoch 13/100, Loss: 0.9114, LR: 0.001000
Epoch 14/100, Loss: 0.9120, LR: 0.001000
Epoch 15/100, Loss: 0.9127, LR: 0.001000
Epoch 16/100, Loss: 0.9304, LR: 0.001000
Epoch 17/100, Loss: 0.9261, LR: 0.001000
Epoch 18/100, Loss: 0.9180, LR: 0.001000
Epoch 19/100, Loss: 0.9135, LR: 0.001000
Epoch 20/100, Loss: 0.9115, LR: 0.001000
Epoch 21/100, Loss: 0.9109, LR: 0.001000
Epoch 22/100, Loss: 0.9104, LR: 0.001000
Epoch 23/100, Loss: 0.9104, LR: 0.001000
Epoch 24/100, Loss: 0.9101, LR: 0.001000
Epoch 25/100, Loss: 0.9102, LR: 0.001000
Epoch 26/100, Loss: 0.9102, LR: 0.001000
Epoch 27/100, Loss: 0.9103, LR: 0.001000
Epoch 28/100, Loss: 0.9102, LR: 0.001000
Epoch 29/100, Loss: 0.9103, LR: 0.001000
Epoch 30/100, Loss: 0.9108, LR: 0.001000
Epoch 31/100, Loss: 0.9105, LR: 0.001000
Epoch 32/100, Loss: 0.9111, LR: 0.001000
Epoch 33/100, Loss: 0.9113, LR: 0.001000
Epoch 34/100, Loss: 0.9220, LR: 0.001000
Epoch 35/100, Loss: 0.9254, LR: 0.001000
Epoch 36/100, Loss: 0.9166, LR: 0.001000
Epoch 37/100, Loss: 0.9127, LR: 0.001000
Epoch 38/100, Loss: 0.9116, LR: 0.001000
Epoch 39/100, Loss: 0.9109, LR: 0.001000
Epoch 40/100, Loss: 0.9109, LR: 0.001000
Epoch 41/100, Loss: 0.9107, LR: 0.001000
Epoch 42/100, Loss: 0.9105, LR: 0.001000
Epoch 43/100, Loss: 0.9105, LR: 0.001000
Epoch 44/100, Loss: 0.9104, LR: 0.001000
Epoch 45/100, Loss: 0.9105, LR: 0.001000
Epoch 46/100, Loss: 0.9107, LR: 0.001000
Epoch 47/100, Loss: 0.9105, LR: 0.001000
Epoch 48/100, Loss: 0.9106, LR: 0.001000
Epoch 49/100, Loss: 0.9111, LR: 0.001000
Epoch 50/100, Loss: 0.9115, LR: 0.000500
Epoch 51/100, Loss: 0.9110, LR: 0.000500
Epoch 52/100, Loss: 0.9103, LR: 0.000500
Epoch 53/100, Loss: 0.9103, LR: 0.000500
Epoch 54/100, Loss: 0.9100, LR: 0.000500
Epoch 55/100, Loss: 0.9101, LR: 0.000500
Epoch 56/100, Loss: 0.9101, LR: 0.000500
Epoch 57/100, Loss: 0.9101, LR: 0.000500
Epoch 58/100, Loss: 0.9102, LR: 0.000500
Epoch 59/100, Loss: 0.9103, LR: 0.000500
Epoch 60/100, Loss: 0.9101, LR: 0.000500
Epoch 61/100, Loss: 0.9103, LR: 0.000500
Epoch 62/100, Loss: 0.9105, LR: 0.000500
Epoch 63/100, Loss: 0.9128, LR: 0.000500
Epoch 64/100, Loss: 0.9119, LR: 0.000500
Epoch 65/100, Loss: 0.9112, LR: 0.000500
Epoch 66/100, Loss: 0.9104, LR: 0.000500
Epoch 67/100, Loss: 0.9102, LR: 0.000500
Epoch 68/100, Loss: 0.9100, LR: 0.000500
Epoch 69/100, Loss: 0.9100, LR: 0.000500
Epoch 70/100, Loss: 0.9099, LR: 0.000500
Epoch 71/100, Loss: 0.9098, LR: 0.000500
Epoch 72/100, Loss: 0.9100, LR: 0.000500
Epoch 73/100, Loss: 0.9100, LR: 0.000500
Epoch 74/100, Loss: 0.9101, LR: 0.000500
Epoch 75/100, Loss: 0.9101, LR: 0.000500
Epoch 76/100, Loss: 0.9101, LR: 0.000500
Epoch 77/100, Loss: 0.9101, LR: 0.000500
Epoch 78/100, Loss: 0.9101, LR: 0.000500
Epoch 79/100, Loss: 0.9113, LR: 0.000500
Epoch 80/100, Loss: 0.9113, LR: 0.000250
Epoch 81/100, Loss: 0.9102, LR: 0.000250
Epoch 82/100, Loss: 0.9103, LR: 0.000250
Epoch 83/100, Loss: 0.9098, LR: 0.000250
Epoch 84/100, Loss: 0.9098, LR: 0.000250
Epoch 85/100, Loss: 0.9100, LR: 0.000250
Epoch 86/100, Loss: 0.9099, LR: 0.000250
Epoch 87/100, Loss: 0.9098, LR: 0.000250
Epoch 88/100, Loss: 0.9097, LR: 0.000250
Epoch 89/100, Loss: 0.9098, LR: 0.000250
Epoch 90/100, Loss: 0.9098, LR: 0.000250
Epoch 91/100, Loss: 0.9097, LR: 0.000250
Epoch 92/100, Loss: 0.9099, LR: 0.000250
Epoch 93/100, Loss: 0.9098, LR: 0.000250
Epoch 94/100, Loss: 0.9096, LR: 0.000250
Epoch 95/100, Loss: 0.9099, LR: 0.000250
Epoch 96/100, Loss: 0.9098, LR: 0.000250
Epoch 97/100, Loss: 0.9098, LR: 0.000250
Epoch 98/100, Loss: 0.9098, LR: 0.000250
Epoch 99/100, Loss: 0.9097, LR: 0.000250
Epoch 100/100, Loss: 0.9098, LR: 0.000250
Model saved to ./model/latest.pth

Evaluate 1/100
Evaluate 2/100
Evaluate 3/100
Evaluate 4/100
Evaluate 5/100
Evaluate 6/100
Evaluate 7/100
Evaluate 8/100
Evaluate 9/100
Evaluate 10/100
Evaluate 11/100
Evaluate 12/100
Evaluate 13/100
Evaluate 14/100
Evaluate 15/100
Evaluate 16/100
Evaluate 17/100
Evaluate 18/100
Evaluate 19/100
Evaluate 20/100
Evaluate 21/100
Evaluate 22/100
Evaluate 23/100
Evaluate 24/100
Evaluate 25/100
Evaluate 26/100
Evaluate 27/100
Evaluate 28/100
Evaluate 29/100
Evaluate 30/100
Evaluate 31/100
Evaluate 32/100
Evaluate 33/100
Evaluate 34/100
Evaluate 35/100
Evaluate 36/100
Evaluate 37/100
Evaluate 38/100
Evaluate 39/100
Evaluate 40/100
Evaluate 41/100
Evaluate 42/100
Evaluate 43/100
Evaluate 44/100
Evaluate 45/100
Evaluate 46/100
Evaluate 47/100
Evaluate 48/100
Evaluate 49/100
Evaluate 50/100
Evaluate 51/100
Evaluate 52/100
Evaluate 53/100
Evaluate 54/100
Evaluate 55/100
Evaluate 56/100
Evaluate 57/100
Evaluate 58/100
Evaluate 59/100
Evaluate 60/100
Evaluate 61/100
Evaluate 62/100
Evaluate 63/100
Evaluate 64/100
Evaluate 65/100
Evaluate 66/100
Evaluate 67/100
Evaluate 68/100
Evaluate 69/100
Evaluate 70/100
Evaluate 71/100
Evaluate 72/100
Evaluate 73/100
Evaluate 74/100
Evaluate 75/100
Evaluate 76/100
Evaluate 77/100
Evaluate 78/100
Evaluate 79/100
Evaluate 80/100
Evaluate 81/100
Evaluate 82/100
Evaluate 83/100
Evaluate 84/100
Evaluate 85/100
Evaluate 86/100
Evaluate 87/100
Evaluate 88/100
Evaluate 89/100
Evaluate 90/100
Evaluate 91/100
Evaluate 92/100
Evaluate 93/100
Evaluate 94/100
Evaluate 95/100
Evaluate 96/100
Evaluate 97/100
Evaluate 98/100
Evaluate 99/100
Evaluate 100/100
AveragePoint 0.475
Change BestPlayer
>> Model updated (win rate: 47.5%)

Evaluate 1/10
Evaluate 2/10
Evaluate 3/10
Evaluate 4/10
Evaluate 5/10
Evaluate 6/10
Evaluate 7/10
Evaluate 8/10
Evaluate 9/10
Evaluate 10/10
VS_Random 0.4
>> Cycle 5 completed. Checkpoint saved.

Train 6 ====================================
>> Game Count: 500
>> MCTS Simulations: 100
>> Learning Rate: 0.001
>> Starting parallel self-play with 8 workers (C++ backend)
>> Total games: 500, Games per worker: 62
>> MCTS batch size: 32, PV evaluate count: 100
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 8: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 3: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 4: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 1: 10/63 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 5: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 7: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 6: 10/62 games completed
Using C++ backend for MCTS
>> CUDA optimizations enabled:
   - TF32: True
   - cuDNN benchmark: True
>> PyTorch CPU threads: 6
Worker 2: 10/63 games completed
Worker 3: 20/63 games completed
Worker 8: 20/62 games completed
Worker 1: 20/63 games completed
Worker 4: 20/63 games completed
Worker 6: 20/62 games completed
Worker 7: 20/62 games completed
Worker 5: 20/62 games completed
Worker 2: 20/63 games completed
Worker 6: 30/62 games completed
Worker 8: 30/62 games completed
Worker 4: 30/63 games completed
Worker 3: 30/63 games completed
Worker 5: 30/62 games completed
Worker 7: 30/62 games completed
Worker 1: 30/63 games completed
Worker 2: 30/63 games completed
Worker 3: 40/63 games completed
Worker 8: 40/62 games completed
Worker 7: 40/62 games completed
Worker 5: 40/62 games completed
Worker 6: 40/62 games completed
Worker 4: 40/63 games completed
Worker 2: 40/63 games completed
Worker 1: 40/63 games completed
Worker 3: 50/63 games completed
Worker 5: 50/62 games completed
Worker 8: 50/62 games completed
Worker 6: 50/62 games completed
Worker 7: 50/62 games completed
Worker 4: 50/63 games completed
Worker 2: 50/63 games completed
Worker 1: 50/63 games completed
Worker 3: 60/63 games completed
Worker 8: 60/62 games completed
Worker 2: 60/63 games completed
Worker 6: 60/62 games completed
Worker 5: 60/62 games completed
Worker 7: 60/62 games completed
Worker 4: 60/63 games completed
Worker 1: 60/63 games completed
>> Collected 23978 training samples from 500 games
>> Saved to ./data/20251030165039.history
>> Train 6
>> Learning Rate: 0.001
Epoch 1/100, Loss: 0.9329, LR: 0.001000
Epoch 2/100, Loss: 0.9125, LR: 0.001000
Epoch 3/100, Loss: 0.9066, LR: 0.001000
Epoch 4/100, Loss: 0.9018, LR: 0.001000
Epoch 5/100, Loss: 0.9000, LR: 0.001000
Epoch 6/100, Loss: 0.9005, LR: 0.001000
Epoch 7/100, Loss: 0.9003, LR: 0.001000
Epoch 8/100, Loss: 0.9021, LR: 0.001000
Epoch 9/100, Loss: 0.9097, LR: 0.001000
Epoch 10/100, Loss: 0.9010, LR: 0.001000
Epoch 11/100, Loss: 0.8996, LR: 0.001000
Epoch 12/100, Loss: 0.8981, LR: 0.001000
Epoch 13/100, Loss: 0.8982, LR: 0.001000
Epoch 14/100, Loss: 0.8974, LR: 0.001000
Epoch 15/100, Loss: 0.8974, LR: 0.001000
Epoch 16/100, Loss: 0.8976, LR: 0.001000
Epoch 17/100, Loss: 0.8971, LR: 0.001000
Epoch 18/100, Loss: 0.8978, LR: 0.001000
Epoch 19/100, Loss: 0.8984, LR: 0.001000
Epoch 20/100, Loss: 0.8986, LR: 0.001000
Epoch 21/100, Loss: 0.8989, LR: 0.001000
Epoch 22/100, Loss: 0.9139, LR: 0.001000
Epoch 23/100, Loss: 0.9038, LR: 0.001000
Epoch 24/100, Loss: 0.9001, LR: 0.001000
Epoch 25/100, Loss: 0.8986, LR: 0.001000
Epoch 26/100, Loss: 0.8985, LR: 0.001000
Epoch 27/100, Loss: 0.8978, LR: 0.001000
Epoch 28/100, Loss: 0.8971, LR: 0.001000
Epoch 29/100, Loss: 0.8977, LR: 0.001000
Epoch 30/100, Loss: 0.8975, LR: 0.001000
Epoch 31/100, Loss: 0.8975, LR: 0.001000
Epoch 32/100, Loss: 0.8967, LR: 0.001000
Epoch 33/100, Loss: 0.8970, LR: 0.001000
Epoch 34/100, Loss: 0.8968, LR: 0.001000
Epoch 35/100, Loss: 0.8974, LR: 0.001000
Epoch 36/100, Loss: 0.8976, LR: 0.001000
Epoch 37/100, Loss: 0.8971, LR: 0.001000
Epoch 38/100, Loss: 0.8973, LR: 0.001000
Epoch 39/100, Loss: 0.8980, LR: 0.001000
Epoch 40/100, Loss: 0.8987, LR: 0.001000
Epoch 41/100, Loss: 0.9026, LR: 0.001000
Epoch 42/100, Loss: 0.9171, LR: 0.001000
Epoch 43/100, Loss: 0.9024, LR: 0.001000
Epoch 44/100, Loss: 0.9008, LR: 0.001000
Epoch 45/100, Loss: 0.9004, LR: 0.001000
Epoch 46/100, Loss: 0.9003, LR: 0.001000
Epoch 47/100, Loss: 0.9002, LR: 0.001000
Epoch 48/100, Loss: 0.8996, LR: 0.001000
Epoch 49/100, Loss: 0.9004, LR: 0.001000
Epoch 50/100, Loss: 0.8999, LR: 0.000500
Epoch 51/100, Loss: 0.8998, LR: 0.000500
Epoch 52/100, Loss: 0.8993, LR: 0.000500
Epoch 53/100, Loss: 0.8999, LR: 0.000500
Epoch 54/100, Loss: 0.9045, LR: 0.000500
Epoch 55/100, Loss: 0.9009, LR: 0.000500
Epoch 56/100, Loss: 0.9002, LR: 0.000500
Epoch 57/100, Loss: 0.8999, LR: 0.000500
Epoch 58/100, Loss: 0.8992, LR: 0.000500
Epoch 59/100, Loss: 0.8976, LR: 0.000500
Epoch 60/100, Loss: 0.8978, LR: 0.000500
Epoch 61/100, Loss: 0.8972, LR: 0.000500
Epoch 62/100, Loss: 0.8982, LR: 0.000500
Epoch 63/100, Loss: 0.8977, LR: 0.000500
Epoch 64/100, Loss: 0.8972, LR: 0.000500
Epoch 65/100, Loss: 0.8978, LR: 0.000500
Epoch 66/100, Loss: 0.8974, LR: 0.000500
Epoch 67/100, Loss: 0.8981, LR: 0.000500
Epoch 68/100, Loss: 0.8973, LR: 0.000500
Epoch 69/100, Loss: 0.8977, LR: 0.000500
Epoch 70/100, Loss: 0.8974, LR: 0.000500
Epoch 71/100, Loss: 0.8977, LR: 0.000500
Epoch 72/100, Loss: 0.8975, LR: 0.000500
Epoch 73/100, Loss: 0.8977, LR: 0.000500
Epoch 74/100, Loss: 0.8976, LR: 0.000500
Epoch 75/100, Loss: 0.8973, LR: 0.000500
Epoch 76/100, Loss: 0.8975, LR: 0.000500
Epoch 77/100, Loss: 0.8976, LR: 0.000500
Epoch 78/100, Loss: 0.8977, LR: 0.000500
Epoch 79/100, Loss: 0.8975, LR: 0.000500
Epoch 80/100, Loss: 0.8985, LR: 0.000250
Epoch 81/100, Loss: 0.8975, LR: 0.000250
Epoch 82/100, Loss: 0.8975, LR: 0.000250
Epoch 83/100, Loss: 0.8974, LR: 0.000250
Epoch 84/100, Loss: 0.8972, LR: 0.000250
Epoch 85/100, Loss: 0.8975, LR: 0.000250
Epoch 86/100, Loss: 0.8971, LR: 0.000250
Epoch 87/100, Loss: 0.8973, LR: 0.000250
Epoch 88/100, Loss: 0.8973, LR: 0.000250
Epoch 89/100, Loss: 0.8972, LR: 0.000250
Epoch 90/100, Loss: 0.8971, LR: 0.000250
Epoch 91/100, Loss: 0.8971, LR: 0.000250
Epoch 92/100, Loss: 0.8974, LR: 0.000250
Epoch 93/100, Loss: 0.8977, LR: 0.000250
Epoch 94/100, Loss: 0.8979, LR: 0.000250
Epoch 95/100, Loss: 0.8974, LR: 0.000250
Epoch 96/100, Loss: 0.8974, LR: 0.000250
Epoch 97/100, Loss: 0.8977, LR: 0.000250
Epoch 98/100, Loss: 0.8974, LR: 0.000250
Epoch 99/100, Loss: 0.8967, LR: 0.000250
Epoch 100/100, Loss: 0.8977, LR: 0.000250
Model saved to ./model/latest.pth

Evaluate 1/100
Evaluate 2/100
Evaluate 3/100
Evaluate 4/100
Evaluate 5/100
Evaluate 6/100
Evaluate 7/100
Evaluate 8/100
Evaluate 9/100
Evaluate 10/100
Evaluate 11/100
Evaluate 12/100
Evaluate 13/100
Evaluate 14/100
Evaluate 15/100
Evaluate 16/100
Evaluate 17/100
Evaluate 18/100
Evaluate 19/100
Evaluate 20/100
Evaluate 21/100
Evaluate 22/100
Evaluate 23/100
Evaluate 24/100
Evaluate 25/100
Evaluate 26/100
Evaluate 27/100
Evaluate 28/100
Evaluate 29/100
Evaluate 30/100
Evaluate 31/100
Evaluate 32/100
Evaluate 33/100
Evaluate 34/100
Evaluate 35/100
Evaluate 36/100
Evaluate 37/100
Evaluate 38/100
Evaluate 39/100
Evaluate 40/100
Evaluate 41/100
Evaluate 42/100
Evaluate 43/100
Evaluate 44/100
Evaluate 45/100
Evaluate 46/100
Evaluate 47/100
Evaluate 48/100
Evaluate 49/100
Evaluate 50/100
Evaluate 51/100
Evaluate 52/100
Evaluate 53/100
Evaluate 54/100
Evaluate 55/100
Evaluate 56/100
Evaluate 57/100
Evaluate 58/100
Evaluate 59/100
Evaluate 60/100
Evaluate 61/100
Evaluate 62/100
Evaluate 63/100
Evaluate 64/100
Evaluate 65/100
Evaluate 66/100
Evaluate 67/100
Evaluate 68/100
Evaluate 69/100
Evaluate 70/100
Evaluate 71/100
Evaluate 72/100
Evaluate 73/100
Evaluate 74/100
Evaluate 75/100
Evaluate 76/100
Evaluate 77/100
Evaluate 78/100
Evaluate 79/100
Evaluate 80/100
Evaluate 81/100
Evaluate 82/100
Evaluate 83/100
Evaluate 84/100
Evaluate 85/100
Evaluate 86/100
Evaluate 87/100
Evaluate 88/100
Evaluate 89/100
Evaluate 90/100
Evaluate 91/100
Evaluate 92/100
Evaluate 93/100
Evaluate 94/100
Evaluate 95/100
Evaluate 96/100
Evaluate 97/100
Evaluate 98/100
Evaluate 99/100
Evaluate 100/100
AveragePoint 0.51
Change BestPlayer
>> Model updated (win rate: 51.0%)

Evaluate 1/10
Evaluate 2/10
Evaluate 3/10
Evaluate 4/10
Evaluate 5/10
Evaluate 6/10
Evaluate 7/10
Evaluate 8/10
Evaluate 9/10
Evaluate 10/10
VS_Random 0.5
>> Cycle 6 completed. Checkpoint saved.

Train 7 ====================================
>> Game Count: 500
>> MCTS Simulations: 100
>> Learning Rate: 0.001
>> Starting parallel self-play with 8 workers (C++ backend)
>> Total games: 500, Games per worker: 62
>> MCTS batch size: 32, PV evaluate count: 100
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
Using GPU: NVIDIA GeForce RTX 4070 Ti
Using C++ backend for MCTS
>> Using parallel C++ backend for maximum speed!
